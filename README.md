# ISE_microfossil
# Radiolaria Image Classification  
**Deep Learning for Southern Ocean Radiolarian Microfossil Identification**

This repository contains all code, experiments, and visualizations for a 32-class radiolarian microfossil image classification task.  
The project compares **Vision Transformer (ViT)** and **ResNet34** under multiple configurations, including data augmentation and transfer learning.

---

## ğŸ“‚ Project Structure


251104hw/
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ train_baseline.py # Baseline ViT training
â”‚ â”œâ”€â”€ train_resnet34.py # ResNet34 + augmentation
â”‚ â”œâ”€â”€ visualize_resnet34.py # All visualizations (Plotly + Seaborn)
â”‚ â””â”€â”€ utils.py # Dataset loader, transforms, helpers
â”‚
â”œâ”€â”€ data/ # Original dataset (ignored by Git)
â”‚
â”œâ”€â”€ models/ # Saved .pt model files (ignored)
â”‚
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ confusion_matrix.html # Interactive Plotly confusion matrix
â”‚ â”œâ”€â”€ classification_report.csv
â”‚ â”œâ”€â”€ training_curves.png (if exists)
â”‚ â””â”€â”€ other visualizations
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


---

# ğŸ“Œ 1. Overview

Radiolarians are silica-based plankton whose fossil records provide essential paleoceanographic and paleoclimate signals.  
This project aims to create a robust classifier capable of identifying **32 radiolarian morphotypes** from microscope images.

**We conducted three experiments:**

| Experiment | Model | Data Augmentation | Epochs | Result |
|-----------|--------|------------------|--------|--------|
| **Exp 1** | Baseline ViT | âŒ No | 2 | **91.40%** accuracy |
| **Exp 2** | ViT + Aggressive Augmentation | âœ”ï¸ Yes | 2 | **20.87%**, training collapsed |
| **Exp 3** | ResNet34 + Augmentation | âœ”ï¸ Yes | 20 | **â‰ˆ91%** accuracy + best stability |

---

# ğŸš€ 2. Installation

## 2.1 Create Virtual Environment (recommended)

```bash
conda create -n radiolaria python=3.10
conda activate radiolaria

2.2 Install Dependencies
pip install -r requirements.txt


If you want visualization support:

pip install plotly seaborn matplotlib

ğŸ§  3. Training
3.1 Experiment 1 â€” Baseline ViT
python3 scripts/train_baseline.py


Output example:

Using device: CPU
Epoch 1/2, Train Loss: 0.7244
Epoch 2/2, Train Loss: 0.3200
Test Accuracy: 91.40%
Model saved to models/baseline_vit.pt

3.2 Experiment 2 â€” ViT + Augmentation (Degraded)
python3 scripts/train_baseline.py --aug on


Output:

Epoch 1/2, Loss=3.0296
Epoch 2/2, Loss=3.0070
Test Accuracy: 20.87%


âš ï¸ Model collapse explanation

Augmentation pipeline was too strong

ViT is sensitive to small-scale distortions

Training epochs (2) insufficient

No warmup or LR scheduling

Likely underfitting + over-regularization

3.3 Experiment 3 â€” ResNet34 + Augmentation
python3 scripts/train_resnet34.py


This experiment achieved stable performance (~91% accuracy) with better convergence property.

ğŸ“Š 4. Visualization & Analysis

All visualizations are generated by:

python3 scripts/visualize_resnet34.py


Outputs include:

âœ” confusion_matrix.html

Interactive Plotly heatmap

Hover to inspect class-wise performance

Best placed in your Analysis / Results section of the report

âœ” classification_report.csv

Precision/recall/F1 for all 32 classes

Used to create:

Bar charts

Radar plots (performance per class)

Macro vs weighted comparisons

âœ” training curves (if training logs available)

Loss vs epochs

Accuracy vs epochs

Helps show underfitting / convergence trends

Place these figures in sections:

Visualization	Recommended Section
Confusion Matrix	Results â†’ Error Analysis
PR/F1 Bar Chart	Results â†’ Per-class Performance
Training Curves	Methods â†’ Model Training Analysis
HTML Interactive Charts	Appendix or Supplementary Materials
ğŸ”¬ 5. Dataset

Original split: train/, val/, test/

Resized folders: generated automatically

train_resized/

val_resized/

test_resized/

All resized images are 224 Ã— 224 (ViT / ResNet baseline size).

ğŸ“ˆ 6. Results Summary
Model	Augmentation	Accuracy	Notes
ViT (baseline)	âŒ	91.40%	Surprisingly strong even with minimal training
ViT (augmented)	âœ”ï¸	20.87%	Over-augmentation collapsed training
ResNet34 (aug aug)	âœ”ï¸	~91%	Best stability, robust generalization
ğŸ“ 7. Reproducibility

To reproduce all figures:

cd scripts
python3 visualize_resnet34.py


To retrain models:

python3 train_baseline.py
python3 train_resnet34.py

ğŸ“¦ 8. Acknowledgments

SO32 Radiolarian dataset (Southern Ocean microfossils)

PyTorch team

Contributors who provided morphological taxonomy definitions

ğŸ“œ 9. License

MIT License.
